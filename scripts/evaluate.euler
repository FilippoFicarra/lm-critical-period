#!/bin/bash

#SBATCH -n 1
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=16000
#SBATCH --gpus=8
#SBATCH --time=23:00:00
#SBATCH --open-mode=truncate
#SBATCH --mail-type=END,FAIL


#! Model directory (i.e. where the model checkpoints are saved):
modeldir="/cluster/work/cotterell/iconstantine/lm-critical-period/checkpoints"

export WANDB_PROJECT="evaluation"
export WANDB__SERVICE_WAIT=300

#! Run options for the application:
case $TASK in

  blimp)
    workdir="/cluster/work/cotterell/iconstantine/evaluation-pipeline"
    prefix="python3"
    application="babylm_eval.py"
    options="$modeldir/${MODEL} ${MODEL_TYPE}"
    ;;

  blimp_checkpoints)
    workdir="/cluster/work/cotterell/iconstantine/lm-critical-period"

    for checkpoint in $workdir/checkpoints/${MODEL}/checkpoint-*; do
      if [ "$MODEL_TYPE" = decoder ]
      then
        echo -e "\nFixing tokenizer config for $checkpoint"
        python3 ./src/learn/fix_tokenizer.py $checkpoint
      fi

      CMD="${workdir}/scripts/evaluate.sh blimp ${checkpoint#*checkpoints/} ${MODEL_TYPE}"
      echo $CMD
      eval $CMD
      sleep 480
    done
    echo -e "\n"

    prefix=""
    application="echo"
    options="Started ${LANG} evaluation for each checkpoint of ${MODEL}"
    ;;

  glue)
    workdir="/cluster/work/cotterell/iconstantine/evaluation-pipeline"
    prefix=""
    application="./finetune_all_tasks.sh"
    options="$modeldir/${MODEL} 5e-5 10 32"
    ;;

  fisher)
    workdir="/cluster/work/cotterell/iconstantine/lm-critical-period"
    prefix="MODEL_NAME=${MODEL} DATA_DIR=data/unified_clean/${LANG}  SEED=42"
    application="src/learn/eval_${MODEL_TYPE}.sh"
    options="--estimate_fisher_matrix"
    ;;

  l1)
    workdir="/cluster/work/cotterell/iconstantine/lm-critical-period"
    prefix="MODEL_NAME=${MODEL} DATA_DIR=data/unified_clean/${LANG}  SEED=42"
    application="src/learn/eval_${MODEL_TYPE}.sh"
    options=""
    ;;

  l1_checkpoints)
    workdir="/cluster/work/cotterell/iconstantine/lm-critical-period"

    for checkpoint in $workdir/checkpoints/${MODEL}/checkpoint-*; do
      CMD="${workdir}/scripts/evaluate.sh l1 ${checkpoint#*checkpoints/} ${MODEL_TYPE} ${LANG}"
      echo $CMD
      eval $CMD
    done
    echo -e "\n"

    prefix=""
    application="echo"
    options="Started ${LANG} evaluation for each checkpoint of ${MODEL}"
    ;;

  *)
    echo -n "unknown model name"
    ;;
esac


module purge
module load eth_proxy gcc/8.2.0 python_gpu/3.9.9
source $workdir/venv/bin/activate


echo -e "JobID: $SLURM_JOB_ID\n======"
echo "Time: `date`"
echo "Running on master node: `hostname`"
echo "Current directory: `pwd`"

cd $workdir
echo -e "Changed directory to `pwd`.\n"

CMD="$prefix $application $options"
echo -e "\nExecuting command:\n==================\n$CMD\n"
eval $CMD
